import os
HF_CACHE_DIR = "/root/autodl-tmp/hf_cache"
os.makedirs(HF_CACHE_DIR, exist_ok=True)

os.environ["HF_HOME"] = HF_CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = HF_CACHE_DIR
os.environ["HUGGINGFACE_HUB_CACHE"] = HF_CACHE_DIR
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import re
import json
import random
import time
import shutil
import torch
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

from datasets import load_dataset
from vllm import LLM, SamplingParams
from sentence_transformers import SentenceTransformer
import chromadb
from openai import OpenAI

# ================= é…ç½®åŒºåŸŸ =================
DEEPSEEK_API_KEY = "" 
DEEPSEEK_BASE_URL = "https://api.deepseek.com"

STUDENT_MODEL_PATH = "Qwen/Qwen2.5-Math-0.5B"
DB_PATH = "./math_notebook_db"
SAMPLE_SIZE = 7000         # å¢å¤§æ ·æœ¬é‡ä»¥å‘æŒ¥å¹¶å‘ä¼˜åŠ¿
MAX_RETRY_ROUNDS = 3       
TEACHER_CONCURRENCY = 15   # DeepSeek API çš„å¹¶å‘çº¿ç¨‹æ•° (æ ¹æ®ä½ çš„API Rate Limitè°ƒæ•´)

# ================= 1. çŸ¥è¯†åº“ç®¡ç† =================
class MathNotebookDB:
    def __init__(self, reset=False):
        if reset and os.path.exists(DB_PATH):
            shutil.rmtree(DB_PATH)
        self.client = chromadb.PersistentClient(path=DB_PATH)
        # æœ€ç»ˆçš„é«˜è´¨é‡ç»éªŒåº“
        self.collection = self.client.get_or_create_collection(name="elite_strategies")
        
        # ä¸´æ—¶é”™é¢˜æ£€ç´¢åº“ (ç”¨äºæ³›åŒ–éªŒè¯)
        self.failed_collection = self.client.get_or_create_collection(name="temp_failed_cases")
        
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2', device="cpu")

    def index_failed_cases(self, failed_cases):
        """å°†é”™é¢˜å»ºç«‹ä¸´æ—¶ç´¢å¼•ï¼Œç”¨äºåç»­çš„æ³›åŒ–éªŒè¯"""
        if not failed_cases: return
        print("ğŸ§  æ­£åœ¨æ„å»ºé”™é¢˜å‘é‡ç´¢å¼• (ç”¨äºæ³›åŒ–éªŒè¯)...")
        
        ids = [str(c['id']) for c in failed_cases]
        documents = [c['question'] for c in failed_cases]
        embeddings = self.embedder.encode(documents).tolist()
        # å­˜ GT æ–¹ä¾¿éªŒè¯
        metadatas = [{"ground_truth": c['ground_truth']} for c in failed_cases]
        
        # å…ˆæ¸…ç©ºæ—§çš„
        try:
            self.client.delete_collection("temp_failed_cases")
            self.failed_collection = self.client.create_collection("temp_failed_cases")
        except:
            pass
            
        self.failed_collection.add(ids=ids, embeddings=embeddings, documents=documents, metadatas=metadatas)

    def search_similar_failed_case(self, trigger_text, exclude_id):
        """æ ¹æ® Trigger æœç´¢ç›¸ä¼¼çš„é”™é¢˜"""
        embedding = self.embedder.encode(trigger_text).tolist()
        # æœ 2 ä¸ªï¼Œé˜²æ­¢ç¬¬ 1 ä¸ªæ˜¯è‡ªå·±
        results = self.failed_collection.query(query_embeddings=[embedding], n_results=2)
        
        if not results['ids'][0]: return None
        
        for i, found_id in enumerate(results['ids'][0]):
            if str(found_id) != str(exclude_id):
                return {
                    "id": int(found_id),
                    "question": results['documents'][0][i],
                    "ground_truth": results['metadatas'][0][i]['ground_truth']
                }
        return None

    def save_experience_batch(self, experiences):
        if not experiences: return
        triggers = [e['trigger'] for e in experiences]
        embeddings = self.embedder.encode(triggers).tolist()
        ids = [f"exp_{int(time.time())}_{random.randint(10000,99999)}_{i}" for i in range(len(experiences))]
        documents = [e['rule_text'] for e in experiences]
        metadatas = [{"trigger": e['trigger'], "source_question": e['original_q'][:200]} for e in experiences]
        self.collection.add(ids=ids, embeddings=embeddings, documents=documents, metadatas=metadatas)
        print(f"ğŸ’¾ [å…¥åº“] {len(experiences)} æ¡ç»éªŒé€šè¿‡åŒé‡éªŒè¯ï¼Œå·²å­˜å…¥çŸ¥è¯†åº“")

# ================= 2. å¯¼å¸ˆä»£ç† =================
class DeepSeekTeacher:
    def __init__(self):
        self.client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)

    def _call_api_single(self, task_data):
        q = task_data['question']
        wrong_ans = task_data['wrong_ans']
        gt = task_data['ground_truth']
        prev_feedback = task_data.get('feedback')

        system_prompt = """You are a Meta-Cognitive Math Tutor specializing in "Knowledge Distillation". 
Your task is to analyze a specific failure by a Student Model and distill it into a **Universal Cognitive Schema** (Trigger + Strategy) that can be stored in a vector database to solve *any* similar future problems.

### GOAL
Transform a specific wrong answer into a high-level, abstract mathematical intuition.

### INPUT DATA
1. **Problem**: The specific math word problem.
2. **Student Wrong Answer**: The incorrect path taken.
3. **Correct Solution**: The ground truth logic.

### OUTPUT SECTIONS (Strict JSON Format)

#### 1. trigger_scenario (The "Search Key")
**Definition**: A concise, dense description of the *problem structure* and *key concepts* that would make an expert say, "Ah, this is a [Trigger] problem."
**Purpose**: This text will be embedded to retrieve this strategy later.
**Requirements**:
*   Focus on **structural patterns** (e.g., "Relative motion," "Compound ratios," "Work rate with delays").
*   Include key **entity relationships** (e.g., "Two objects moving towards each other," "Part-to-whole comparison").
*   **DO NOT** mention specific objects (like "apples", "cars") or numbers from the problem. Use general terms (entities, items, units).

#### 2. strategy_text (The "Algorithm")
**Definition**: A step-by-step, abstract algorithm to solve this class of problems.
**Requirements**:
*   **ABSTRACT**: Use variables ($N$, $X$, $T_{total}$) instead of specific numbers.
*   **IMPERATIVE**: Write as instructions (e.g., "1. Define variable X as... 2. Set up the equation...").
*   **LOGICAL**: Explain *how* to set up the relationships, not just the arithmetic.
*   **WARNING**: Explicitly point out the conceptual trap the student fell into (e.g., "Do not confuse individual time with total time").

### ONE-SHOT EXAMPLE
**Input Problem**: "John paints a fence in 3 hours. Tom paints it in 6 hours. How long if they work together?"
**Bad Trigger**: "Problem about John and Tom painting fences." (Too specific)
**Good Trigger**: "Work rate problem involving two agents working simultaneously with different individual rates."
**Bad Strategy**: "Divide 6 by 3 and add them." (Wrong and specific)
**Good Strategy**: "1. Determine individual rates: Rate_A = 1/Time_A and Rate_B = 1/Time_B. 2. Calculate combined rate: Rate_Total = Rate_A + Rate_B. 3. Solve for total time: Time_Total = 1 / Rate_Total. Warning: Do not average the times directly; always sum the rates."

### RESPONSE FORMAT
```json
{
    "trigger_scenario": "...",
    "strategy_text": "..."
}
"""
        user_content = f"[Problem]: {q}\n[Correct]: {gt}\n[Student Wrong]: {wrong_ans}"
        if prev_feedback:
            user_content += f"\n[Previous Failed Hint]: {prev_feedback}"

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}],
                temperature=0.7,
                response_format={"type": "json_object"},
                timeout=30
            )
            res_json = json.loads(response.choices[0].message.content)
            return {
                "id": task_data['id'],
                "strategy": res_json.get("strategy_text", ""),
                "trigger": res_json.get("trigger_scenario", ""),
                "success": True
            }
        except Exception as e:
            return {"id": task_data['id'], "success": False, "error": str(e)}

    def batch_teach(self, failed_cases_list):
        print(f"ğŸ‘¨â€ğŸ« å¯¼å¸ˆæ­£åœ¨æ‰¹é‡æ‰¹æ”¹ä½œä¸š (å¹¶å‘æ•°: {TEACHER_CONCURRENCY})...")
        results = []
        with ThreadPoolExecutor(max_workers=TEACHER_CONCURRENCY) as executor:
            future_to_case = {executor.submit(self._call_api_single, case): case for case in failed_cases_list}
            for future in tqdm(as_completed(future_to_case), total=len(failed_cases_list), desc="DeepSeek Teaching"):
                results.append(future.result())
        return {r['id']: r for r in results if r['success']}

# ================= 3. å­¦ç”Ÿä»£ç† =================
class QwenStudent:
    def __init__(self):
        print(f"ğŸ§‘â€ğŸ“ Qwen å­¦ç”Ÿåˆå§‹åŒ– (Batch Mode)...")
        self.llm = LLM(
            model=STUDENT_MODEL_PATH,
            trust_remote_code=True,
            tensor_parallel_size=1,
            gpu_memory_utilization=0.90,
            max_model_len=2048,
            enforce_eager=True
        )
        self.params = SamplingParams(temperature=0.0, max_tokens=512)

    def construct_prompt(self, question, hint=None):
        if hint:
            return f"""<|im_start|>user
Hint from Tutor: {hint}

Question: {question}
Please reason step-by-step, and put your final answer within \\boxed{{}}.<|im_end|>
<|im_start|>assistant
"""
        else:
            return f"<|im_start|>user\nQuestion: {question}\nPlease reason step-by-step, and put your final answer within \\boxed{{}}.<|im_end|>\n<|im_start|>assistant\n"

    def batch_solve(self, input_data):
        """
        input_data: List of dicts {'question': str, 'hint': str (optional)}
        """
        prompts = [self.construct_prompt(item['question'], item.get('hint')) for item in input_data]
        outputs = self.llm.generate(prompts, self.params, use_tqdm=True)
        return [out.outputs[0].text.strip() for out in outputs]

    def construct_abstraction_prompt(self, q):
        """
        [æ ¸å¿ƒ] æŠ½è±¡åŒ– Prompt
        ç›®çš„æ˜¯å»é™¤å™ªéŸ³ï¼Œæå–éª¨æ¶ï¼Œä»¥ä¾¿äºå’ŒçŸ¥è¯†åº“ä¸­çš„ Trigger åŒ¹é…
        """
        return f"""<|im_start|>user
Task: Extract the underlying "Math Pattern" from the problem.
1. Remove specific numbers (replace with X, Y, etc.).
2. Remove entity names (e.g., "John" -> "Person", "Apples" -> "Items").
3. Describe the logical structure concisely.

[Example]
Input: John buys 5 apples for $2 each. Total?
Pattern: Calculating total cost given quantity and unit price.

[Target]
Input: {q}
Pattern:<|im_end|>
<|im_start|>assistant
"""

    def batch_abstraction(self, questions):
        """æ–°å¢ï¼šæ‰¹é‡æŠ½è±¡åŒ–é¢˜ç›®"""
        prompts = []
        for q in questions:
            # è¿™é‡Œè°ƒç”¨ construct_abstraction_prompt æ–¹æ³•
            # æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•éœ€è¦åœ¨å¤–éƒ¨å®šä¹‰æˆ–è€…ä½œä¸ºç±»æ–¹æ³•
            # ä¸ºäº†æ–¹ä¾¿ï¼Œè¿™é‡Œç›´æ¥å†…è” prompt æ„é€ 
            prompt = f"""<|im_start|>user
Task: Extract the underlying "Math Pattern" from the problem.
1. Remove specific numbers (replace with X, Y, etc.).
2. Remove entity names (e.g., "John" -> "Person", "Apples" -> "Items").
3. Describe the logical structure concisely.

[Example]
Input: John buys 5 apples for $2 each. Total?
Pattern: Calculating total cost given quantity and unit price.

[Target]
Input: {q}
Pattern:<|im_end|>
<|im_start|>assistant
"""
            prompts.append(prompt)
            
        outputs = self.llm.generate(prompts, self.params, use_tqdm=True)
        return [out.outputs[0].text.strip() for out in outputs]

# ================= 4. ä¸»æµç¨‹æ§åˆ¶å™¨ =================
class DistillationPipeline:
    def __init__(self):
        self.db = MathNotebookDB(reset=True)
        self.teacher = DeepSeekTeacher()
        self.student = QwenStudent()
        self.dataset = load_dataset("gsm8k", "main")['train']

    def extract_answer(self, text):
        if not text: return None
        text = text.replace(',', '')
        match = re.search(r'\\boxed\{(\-?\d+\.?\d*)\}', text)
        if match: return float(match.group(1))
        matches = re.findall(r'-?\d+\.?\d*', text[-100:])
        if matches: return float(matches[-1])
        return None

    def check_correct(self, pred, gt):
        if "####" in gt: gold = self.extract_answer(gt.split("####")[1])
        else: gold = self.extract_answer(gt)
        val = self.extract_answer(pred)
        if gold is None or val is None: return False
        return abs(gold - val) < 1e-4

    def run(self):
        # 1. æ•°æ®å‡†å¤‡
        indices = list(range(len(self.dataset)))
        random.shuffle(indices)
        selected_indices = indices[:SAMPLE_SIZE]
        
        batch_data = []
        for i in selected_indices:
            batch_data.append({
                "id": i,
                "question": self.dataset[i]['question'],
                "ground_truth": self.dataset[i]['answer'],
                "status": "pending", 
                "hint": None,
                "feedback": None
            })

        print(f"ğŸš€ åŒé‡éªŒè¯è’¸é¦å¼€å§‹ (N={SAMPLE_SIZE})...")

        # ================= Phase 1: æ‰¹é‡è£¸è·‘ç­›é€‰é”™é¢˜ =================
        print("\n[Phase 1] æ‰¹é‡è£¸è€ƒ (Base Run)...")
        base_answers = self.student.batch_solve(batch_data)
        
        active_failed_cases = []
        for i, ans in enumerate(base_answers):
            item = batch_data[i]
            if not self.check_correct(ans, item['ground_truth']):
                item['wrong_ans'] = ans
                active_failed_cases.append(item)
        
        print(f"   -> é”™é¢˜æ•°: {len(active_failed_cases)} / {SAMPLE_SIZE}")

        # å°†é”™é¢˜å»ºç«‹ç´¢å¼•ï¼Œä¾›åç»­æ³›åŒ–éªŒè¯ä½¿ç”¨
        # ğŸ”´ [ä¿®æ”¹ç‚¹] å»ºç«‹ç´¢å¼•æ—¶ï¼Œå…ˆå¯¹é”™é¢˜è¿›è¡ŒæŠ½è±¡åŒ–ï¼Œç”¨æŠ½è±¡åçš„æ–‡æœ¬å»ºç´¢å¼•
        print("ğŸ§  æ­£åœ¨å¯¹é”™é¢˜è¿›è¡ŒæŠ½è±¡åŒ–ä»¥æ„å»ºç´¢å¼•...")
        failed_questions = [c['question'] for c in active_failed_cases]
        abstracted_questions = self.student.batch_abstraction(failed_questions)
        
        # å°†æŠ½è±¡åçš„æ–‡æœ¬å›å¡«åˆ° failed_cases ä¸­ï¼Œæ–¹ä¾¿åç»­ç´¢å¼•
        for i, c in enumerate(active_failed_cases):
            c['abstract_question'] = abstracted_questions[i]
            
        # ä¿®æ”¹ MathNotebookDB.index_failed_cases æ–¹æ³•è°ƒç”¨
        # è¿™é‡Œéœ€è¦ç¨å¾®ä¿®æ”¹ index_failed_cases çš„å®ç°é€»è¾‘ï¼Œè®©å®ƒä½¿ç”¨ abstract_question
        self.db.index_failed_cases(active_failed_cases)

        # ================= Phase 2: å¾ªç¯è’¸é¦ =================
        for round_idx in range(1, MAX_RETRY_ROUNDS + 1):
            if not active_failed_cases: break
                
            print(f"\n[Round {round_idx}] æ­£åœ¨å¤„ç† {len(active_failed_cases)} é“é”™é¢˜...")

            # A. Teacher ä»‹å…¥
            teacher_results = self.teacher.batch_teach(active_failed_cases)
            
            ready_to_solve_cases = []
            for case in active_failed_cases:
                if case['id'] in teacher_results:
                    res = teacher_results[case['id']]
                    case['hint'] = res['strategy']
                    case['trigger'] = res['trigger'] 
                    ready_to_solve_cases.append(case)
            
            if not ready_to_solve_cases: break

            # B. Student é‡åšåŸé¢˜ (Primary Verification)
            print(f"   âœï¸ å­¦ç”Ÿé‡åšåŸé¢˜...")
            new_answers = self.student.batch_solve(ready_to_solve_cases)

            # C. ç­›é€‰åŸé¢˜åšå¯¹çš„ï¼Œå‡†å¤‡è¿›è¡Œæ³›åŒ–éªŒè¯
            candidates_for_generalization = [] # (case, rule)
            still_failed_cases = []
            
            for i, ans in enumerate(new_answers):
                case = ready_to_solve_cases[i]
                if self.check_correct(ans, case['ground_truth']):
                    # åŸé¢˜åšå¯¹äº†ï¼Œè¿›å…¥æ³›åŒ–å€™é€‰é˜Ÿåˆ—
                    candidates_for_generalization.append(case)
                else:
                    # è¿˜æ˜¯é”™ï¼Œæ›´æ–° feedback
                    case['feedback'] = f"Hint: '{case['hint']}', Answer: '{ans}' (Wrong)."
                    case['wrong_ans'] = ans
                    still_failed_cases.append(case)

            # D. æ³›åŒ–éªŒè¯ (Generalization Verification)
            # åªæœ‰é€šè¿‡äº†è¿™ä¸€æ­¥ï¼Œæ‰ç®—çœŸæ­£çš„æˆåŠŸ
            final_success_buffer = []
            
            if candidates_for_generalization:
                print(f"   âš”ï¸ æ­£åœ¨å¯¹ {len(candidates_for_generalization)} æ¡ç»éªŒè¿›è¡Œæ³›åŒ–éªŒè¯...")
                
                # 1. ä¸ºæ¯ä¸ª candidate å¯»æ‰¾ç›¸ä¼¼é”™é¢˜ (Neighbor)
                verify_tasks = []
                for case in candidates_for_generalization:
                    # ğŸ”´ [ä¿®æ”¹ç‚¹] ä½¿ç”¨ Trigger (å·²ç»æ˜¯æŠ½è±¡çš„) å»æœ abstract_question ç´¢å¼•
                    neighbor = self.db.search_similar_failed_case(case['trigger'], exclude_id=case['id'])
                    if neighbor:
                        # æ„é€ éªŒè¯ä»»åŠ¡ï¼šç”¨ case çš„ hint å»è§£ neighbor çš„ question
                        verify_tasks.append({
                            "question": neighbor['question'],
                            "hint": case['hint'], # æ ¸å¿ƒï¼šä½¿ç”¨åŸé¢˜çš„ç»éªŒ
                            "ground_truth": neighbor['ground_truth'],
                            "source_case": case # å…³è”å›å»ä»¥ä¾¿ä¿å­˜
                        })
                    else:
                        pass

                # 2. æ‰¹é‡æ‰§è¡Œæ³›åŒ–éªŒè¯
                if verify_tasks:
                    verify_answers = self.student.batch_solve(verify_tasks)
                    
                    for i, v_ans in enumerate(verify_answers):
                        task = verify_tasks[i]
                        if self.check_correct(v_ans, task['ground_truth']):
                            # æ³›åŒ–éªŒè¯é€šè¿‡ï¼
                            final_success_buffer.append({
                                "original_q": task['source_case']['question'],
                                "rule_text": task['source_case']['hint'],
                                "trigger": task['source_case']['trigger']
                            })
            
            # E. å­˜å…¥é€šè¿‡åŒé‡éªŒè¯çš„ç»éªŒ
            if final_success_buffer:
                self.db.save_experience_batch(final_success_buffer)
            
            print(f"   -> åŸé¢˜ä¿®å¤: {len(candidates_for_generalization)} | æ³›åŒ–é€šè¿‡: {len(final_success_buffer)}")
            active_failed_cases = still_failed_cases

        print("\n" + "="*50)
        print("ğŸ† è®­ç»ƒç»“æŸ")

if __name__ == "__main__":
    try:
        import gc
        gc.collect()
        torch.cuda.empty_cache()
    except:
        pass

    pipeline = DistillationPipeline()
    pipeline.run()