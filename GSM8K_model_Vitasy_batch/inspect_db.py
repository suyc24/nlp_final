import chromadb
import json
import os
import pandas as pd
from datetime import datetime
import config

# ================= é…ç½® =================
DB_PATH = config.INSPECT_DB_PATH
COLLECTION_NAME = config.COLLECTION_NAME
EXPORT_FILE = config.EXPORT_FILE

class NotebookInspector:
    def __init__(self):
        if not os.path.exists(DB_PATH):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ•°æ®åº“è·¯å¾„: {DB_PATH}")
            
        print(f"ğŸ“‚ æ­£åœ¨è¿æ¥æ•°æ®åº“: {DB_PATH}...")
        self.client = chromadb.PersistentClient(path=DB_PATH)
        
        try:
            self.collection = self.client.get_collection(name=COLLECTION_NAME)
            print(f"âœ… æˆåŠŸåŠ è½½é›†åˆ: {COLLECTION_NAME}")
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½é›†åˆ '{COLLECTION_NAME}'ã€‚å¯èƒ½æ˜¯åå­—ä¸å¯¹æˆ–åº“ä¸ºç©ºã€‚")
            print(f"   é”™è¯¯ä¿¡æ¯: {e}")
            # åˆ—å‡ºæ‰€æœ‰å¯ç”¨é›†åˆ
            col_list = self.client.list_collections()
            print(f"   ç°æœ‰é›†åˆåˆ—è¡¨: {[c.name for c in col_list]}")
            exit(1)

    def fetch_all(self):
        """æ‹‰å–æ‰€æœ‰æ•°æ®"""
        # include å‚æ•°æŒ‡å®šè¦è·å–å“ªäº›å­—æ®µ
        data = self.collection.get(include=['metadatas', 'documents', 'embeddings'])
        count = len(data['ids'])
        print(f"ğŸ“Š å½“å‰åº“å­˜ç»éªŒæ€»æ•°: {count} æ¡")
        return data

    def display_samples(self, num_samples=5):
        """åœ¨ç»ˆç«¯æ‰“å°å‰ N æ¡æ ·æœ¬"""
        data = self.fetch_all()
        count = len(data['ids'])
        
        print(f"\n=== éšæœºé¢„è§ˆ (å‰ {min(count, num_samples)} æ¡) ===")
        
        for i in range(min(count, num_samples)):
            doc = data['documents'][i]
            meta = data['metadatas'][i]
            id_ = data['ids'][i]
            
            print(f"\n[ID]: {id_}")
            print(f"ğŸ“Œ Trigger (é€‚ç”¨åœºæ™¯): {meta.get('trigger', 'N/A')}")
            print(f"ğŸ’¡ Strategy (ç­–ç•¥): \n{doc}")
            print(f"ğŸ”— Source Question (æ¥æºé¢˜ç‰‡æ®µ): {meta.get('source_question', 'N/A')[:100]}...")
            print("-" * 60)

    def export_to_json(self):
        """å¯¼å‡ºæ‰€æœ‰æ•°æ®åˆ° JSON"""
        data = self.fetch_all()
        count = len(data['ids'])
        
        export_list = []
        for i in range(count):
            item = {
                "id": data['ids'][i],
                "trigger": data['metadatas'][i].get('trigger'),
                "strategy": data['documents'][i],
                "source_question": data['metadatas'][i].get('source_question')
            }
            export_list.append(item)
            
        with open(EXPORT_FILE, 'w', encoding='utf-8') as f:
            json.dump(export_list, f, ensure_ascii=False, indent=2)
            
        print(f"\nâœ… å·²å°†æ‰€æœ‰ {count} æ¡ç»éªŒå¯¼å‡ºè‡³: {os.path.abspath(EXPORT_FILE)}")
        
    def search_by_keyword(self, keyword):
        """ç®€å•çš„å…³é”®è¯æœç´¢ï¼ˆéå‘é‡æœç´¢ï¼Œä»…æ–‡æœ¬åŒ¹é…ï¼‰"""
        print(f"\nğŸ” æ­£åœ¨æœç´¢å…³é”®è¯: '{keyword}' ...")
        data = self.fetch_all()
        found_count = 0
        
        for i in range(len(data['ids'])):
            doc = data['documents'][i]
            meta = data['metadatas'][i]
            trigger = meta.get('trigger', '')
            
            # åœ¨ Trigger æˆ– Strategy ä¸­æœç´¢
            if keyword.lower() in doc.lower() or keyword.lower() in trigger.lower():
                print(f"   Found in [{data['ids'][i]}]: Trigger='{trigger}'")
                found_count += 1
                
        if found_count == 0:
            print("   æœªæ‰¾åˆ°ç›¸å…³ç»éªŒã€‚")

if __name__ == "__main__":
    inspector = NotebookInspector()
    
    # 1. åœ¨ç»ˆç«¯æ˜¾ç¤ºå‰ 5 æ¡
    inspector.display_samples(5)
    
    # 2. å¯¼å‡ºæ‰€æœ‰æ•°æ®
    inspector.export_to_json()