import os
HF_CACHE_DIR = "/root/autodl-tmp/hf_cache"
os.makedirs(HF_CACHE_DIR, exist_ok=True)

os.environ["HF_HOME"] = HF_CACHE_DIR
os.environ["TRANSFORMERS_CACHE"] = HF_CACHE_DIR
os.environ["HUGGINGFACE_HUB_CACHE"] = HF_CACHE_DIR
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import re
import math
from sympy import simplify, parse_expr
from sympy.parsing.latex import parse_latex # åŸºç¡€ç‰ˆ
try:
    from latex2sympy2 import latex2sympy # å¢å¼ºç‰ˆï¼Œå»ºè®®å®‰è£…
except ImportError:
    latex2sympy = None

from func_timeout import func_timeout, FunctionTimedOut
import signal
import json
import httpx
import time
import random
import shutil
import torch
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from openai import OpenAI
from vllm import LLM, SamplingParams
from sentence_transformers import SentenceTransformer
import chromadb
from datasets import load_dataset

# ================= é…ç½®åŒº =================
# ä½ æŒ‡å®šçš„é…ç½®
STUDENT_MODEL_PATH = "Qwen/Qwen2.5-3B-Instruct"
DB_PATH = "./math_notebook_db"
FAILED_CACHE_FILE = "failed_cases_checkpoint.json"
MAX_RETRY_ROUNDS = 3       
TEACHER_CONCURRENCY = 15  
EVALUATOR_CONCURRENCY = 32
SAMPLE_SIZE = 7500

DEEPSEEK_API_KEY = ""
DEEPSEEK_BASE_URL = "https://api.deepseek.com"

VOLC_API_KEY =""
VOLC_ENDPOINT_ID = ""

VALID_TYPES = [
    "Algebra", "Geometry", "Number Theory", "Counting & Probability", 
    "Precalculus", "Calculus", "Linear Algebra"
]

# ================= 1. å¹¶è¡ŒåŒ–æ•°å­¦è¯„æµ‹å™¨ (CPU å¯†é›†å‹) =================
class MathEvaluator:
    def __init__(self, timeout=3):
        """
        :param timeout: å•ä¸ªé¢˜ç›® SymPy éªŒè¯çš„è¶…æ—¶æ—¶é—´(ç§’)
        """
        self.timeout = timeout

    def remove_boxed(self, s):
        """æå– \boxed{...} å†…å®¹"""
        if not s: return None
        if "\\boxed" not in s: return None
        idx = s.rfind("\\boxed{")
        if idx < 0: return None
        i = idx + len("\\boxed{")
        num_open = 1
        for j in range(i, len(s)):
            if s[j] == "{": num_open += 1
            elif s[j] == "}": num_open -= 1
            if num_open == 0: return s[idx + len("\\boxed{"):j]
        return None

    def _clean_latex(self, s):
        """æ ‡å‡†åŒ– LaTeX å­—ç¬¦ä¸²"""
        if not s: return ""
        s = str(s)
        replacements = [
            ("\\$", ""), ("\\text", ""), ("\\mathrm", ""), ("\\ ", ""), ("%", ""),
            ("\\left", ""), ("\\right", ""), ("\\limits", ""), ("Â°", "")
        ]
        for old, new in replacements:
            s = s.replace(old, new)
        s = s.replace("\\dfrac", "\\frac").replace("\\tfrac", "\\frac").replace("\\div", "/")
        return "".join(s.split())

    def _is_number(self, s):
        try:
            float(s)
            return True
        except:
            return False

    def _sympy_check_logic(self, pred_str, gt_str):
        """å®é™…æ‰§è¡Œ SymPy éªŒè¯çš„é€»è¾‘"""
        pred_sym, gt_sym = None, None
        
        # 1. å°è¯•ä½¿ç”¨ latex2sympy2
        if latex2sympy:
            try:
                pred_sym = latex2sympy(pred_str)
                gt_sym = latex2sympy(gt_str)
            except:
                pass
        
        # 2. å›é€€åˆ° SymPy parse_expr
        if pred_sym is None:
            try:
                # ç®€å•çš„å­—ç¬¦æ›¿æ¢ä»¥é€‚é… SymPy è¯­æ³•
                clean_pred = pred_str.replace("^", "**").replace("{", "(").replace("}", ")")
                clean_gt = gt_str.replace("^", "**").replace("{", "(").replace("}", ")")
                pred_sym = parse_expr(clean_pred)
                gt_sym = parse_expr(clean_gt)
            except:
                return False
            
        if pred_sym is None or gt_sym is None:
            return False

        # 3. æ ¸å¿ƒåˆ¤æ–­
        return simplify(pred_sym - gt_sym) == 0

    def verify_single(self, task_tuple):
        """
        å•ä¸ªé¢˜ç›®éªŒè¯å‡½æ•°ï¼Œç”¨äºçº¿ç¨‹æ± è°ƒç”¨
        task_tuple: (prediction, ground_truth)
        """
        pred, gt = task_tuple
        
        pred_inner = self.remove_boxed(pred)
        gt_inner = self.remove_boxed(gt)
        if gt_inner is None: gt_inner = gt # Handle pure text GT
        if pred_inner is None: return False

        norm_pred = self._clean_latex(pred_inner)
        norm_gt = self._clean_latex(gt_inner)

        # Level 1: String Match
        if norm_pred == norm_gt: return True

        # Level 2: Set Match (e.g. "1, 2" == "2, 1")
        if "," in norm_pred and "," in norm_gt:
            try:
                if sorted(norm_pred.split(',')) == sorted(norm_gt.split(',')): return True
            except: pass

        # Level 3: Numeric Match
        if self._is_number(norm_pred) and self._is_number(norm_gt):
            if abs(float(norm_pred) - float(norm_gt)) < 1e-4: return True

        # Level 4: SymPy Match (with timeout)
        try:
            return func_timeout(self.timeout, self._sympy_check_logic, args=(pred_inner, gt_inner))
        except:
            return False

    def batch_verify(self, pred_gt_pairs):
        """
        ğŸš€ å¹¶è¡Œè¯„æµ‹å…¥å£
        """
        if not pred_gt_pairs: return []
        print(f"âš–ï¸ æ­£åœ¨å¹¶è¡Œè¯„æµ‹ {len(pred_gt_pairs)} é“é¢˜ç›® (CPU Threads: {EVALUATOR_CONCURRENCY})...")
        results = [False] * len(pred_gt_pairs)
        
        with ThreadPoolExecutor(max_workers=EVALUATOR_CONCURRENCY) as executor:
            futures = [executor.submit(self.verify_single, pair) for pair in pred_gt_pairs]
            # ä½¿ç”¨ tqdm ç›‘æ§è¯„æµ‹è¿›åº¦
            for i, future in enumerate(tqdm(futures, desc="Evaluating")):
                results[i] = future.result()
        return results

# ================= 2. çŸ¥è¯†åº“ç®¡ç† =================
class MathNotebookDB:
    def __init__(self, reset=False):
        if reset and os.path.exists(DB_PATH):
            shutil.rmtree(DB_PATH)
        self.client = chromadb.PersistentClient(path=DB_PATH)
        self.collection = self.client.get_or_create_collection(name="elite_strategies")
        self.failed_collection = self.client.get_or_create_collection(name="temp_failed_cases")
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2', device="cpu")

    def index_failed_cases(self, failed_cases):
        if not failed_cases: return
        print("ğŸ§  æ­£åœ¨æ„å»ºé”™é¢˜å‘é‡ç´¢å¼•...")
        
        # å¿…é¡»è½¬ä¸º str
        ids = [str(c['id']) for c in failed_cases]
        documents = []
        metadatas = []
        
        for c in failed_cases:
            # ä¼˜å…ˆä½¿ç”¨æŠ½è±¡åçš„ Pattern å»ºç´¢å¼•
            doc_text = c.get('abstraction_pattern', c['question']) 
            documents.append(doc_text)
            
            meta = {
                "ground_truth": str(c['ground_truth']),
                "type": c.get('abstraction_type', 'Unknown'), # å­˜å…¥ç±»å‹ï¼Œæ–¹ä¾¿åç»­æŒ‰ç±»å‹è¿‡æ»¤
                "original_question": c['question'] # æŠŠåŸé¢˜å­˜è¿› metadataï¼Œæ–¹ä¾¿å–å›
            }
            metadatas.append(meta)
        
        embeddings = self.embedder.encode(documents).tolist()
        
        try:
            self.client.delete_collection("temp_failed_cases")
            self.failed_collection = self.client.create_collection("temp_failed_cases")
        except:
            pass
            
        self.failed_collection.add(ids=ids, embeddings=embeddings, documents=documents, metadatas=metadatas)

    # [ä¿®æ”¹] æœç´¢é€»è¾‘
    def search_similar_failed_case(self, trigger_text, exclude_id, filter_type=None):
        """
        :param filter_type: (å¯é€‰) å¼ºåˆ¶åªåœ¨åŒç±»å‹é¢˜ç›®ä¸­æœç´¢
        """
        embedding = self.embedder.encode(trigger_text).tolist()
        
        # æ„é€ è¿‡æ»¤æ¡ä»¶
        where_clause = None
        if filter_type:
            where_clause = {"type": filter_type}

        results = self.failed_collection.query(
            query_embeddings=[embedding], 
            n_results=5,
            where=where_clause # æ”¯æŒç±»å‹è¿‡æ»¤
        )
        
        if not results['ids'] or not results['ids'][0]: return None
        
        for i, found_id in enumerate(results['ids'][0]):
            if str(found_id) != str(exclude_id):
                return {
                    "id": found_id,
                    # æ³¨æ„ï¼šdocumentsé‡Œç°åœ¨æ˜¯ Patternï¼ŒåŸé¢˜åœ¨ metadata é‡Œ
                    "question": results['metadatas'][0][i]['original_question'], 
                    "ground_truth": results['metadatas'][0][i]['ground_truth'],
                    "type": results['metadatas'][0][i]['type']
                }
        return None

    def save_experience_batch(self, experiences):
        if not experiences: return
        ids = [f"exp_{int(time.time())}_{random.randint(10000,99999)}_{i}" for i in range(len(experiences))]
        triggers = [e['trigger'] for e in experiences]
        documents = [e['rule_text'] for e in experiences]
        # è¿™é‡ŒæŠŠ Type ä¹Ÿå­˜è¿›å»äº†
        metadatas = [{
            "trigger": e['trigger'], 
            "source_question": e['original_q'][:200],
            "type": e['type']
        } for e in experiences]
        
        self.collection.add(ids=ids, embeddings=self.embedder.encode(triggers).tolist(), documents=documents, metadatas=metadatas)
        print(f"ğŸ’¾ [å…¥åº“] {len(experiences)} æ¡ç»éªŒå·²å­˜å…¥çŸ¥è¯†åº“")

# ================= 3. å¯¼å¸ˆä»£ç† (DeepSeek) =================
class DeepSeekTeacher:
    def __init__(self):
        http_client = httpx.Client(timeout=60.0) 
        self.client = OpenAI(
            api_key=VOLC_API_KEY,
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            timeout=120.0,
            http_client=http_client
        )

    def _call_api_single(self, task_data):
        q = task_data['question']
        wrong_ans = task_data['wrong_ans']
        gt = task_data['ground_truth']
        prev_feedback = task_data.get('feedback')

        # å®Œæ•´çš„ System Promptï¼ŒåŒ…å« Type åˆ†ç±»æŒ‡ä»¤
        system_prompt = """You are a Fields Medal-level Mathematician acting as a "Cognitive Schema Distiller".
Your goal is to diagnose why a student model failed a complex math problem and distill a **Universal Abstract Schema** that can solve this class of problems.

### INPUT DATA
1. **Problem**: A competition-level math problem (LaTeX format).
2. **Student Wrong Answer**: The incorrect derivation or result.
3. **Correct Solution**: The ground truth proof/solution.

### OUTPUT REQUIREMENTS (Strict JSON)

#### 1. type
**Classify the problem into ONE of these categories**:
["Algebra", "Geometry", "Number Theory", "Counting & Probability", "Precalculus", "Calculus", "Linear Algebra"]

#### 2. trigger_scenario
A concise, structural description of the problem pattern.
*   **BAD**: "A problem about triangle ABC with side 3."
*   **GOOD**: "Geometry: Calculating area of a triangle given two sides and the included angle (SAS)."
*   **NOTE**: Do not use specific numbers. Use mathematical terms.

#### 3. strategy_text
An abstract, algorithmic guide.
*   **Must be step-by-step.**
*   **Must use variables** ($a, b, n$) instead of numbers.
*   **Must highlight the trap** that caused the error.
*   **Format**: "1. Identify variables... 2. Apply Theorem X... Warning: Check discriminant condition."

### RESPONSE FORMAT
```json
{
    "type": "Algebra",
    "trigger_scenario": "...",
    "strategy_text": "..."
}
```
"""
        user_content = f"[Problem]: {q}\n[Correct Solution]: {gt}\n[Student Wrong Trace]: {wrong_ans}"
        if prev_feedback:
            user_content += f"\n[Previous Failed Strategy]: {prev_feedback} (This hint did not work, please refine)"

        try:
            response = self.client.chat.completions.create(
                model=VOLC_ENDPOINT_ID,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}],
                temperature=0.5, 
                response_format={"type": "json_object"},
                timeout=120.0
            )
            res_json = json.loads(response.choices[0].message.content)
            return {
                "id": task_data['id'],
                "type": res_json.get("type", "Algebra"), # è·å–åˆ†ç±»ç»“æœ
                "strategy": res_json.get("strategy_text", ""),
                "trigger": res_json.get("trigger_scenario", ""),
                "success": True
            }
        except Exception as e:
            return {"id": task_data['id'], "success": False, "error": str(e)}

    def batch_teach(self, failed_cases_list):
        print(f"ğŸ‘¨â€ğŸ« å¯¼å¸ˆæ­£åœ¨æ‰¹é‡è¯Šæ–­ (å¹¶å‘æ•°: {TEACHER_CONCURRENCY})...")
        results = {}
        with ThreadPoolExecutor(max_workers=TEACHER_CONCURRENCY) as executor:
            future_to_case = {executor.submit(self._call_api_single, case): case for case in failed_cases_list}
            for future in tqdm(as_completed(future_to_case), total=len(failed_cases_list), desc="DeepSeek Teaching"):
                r = future.result()
                if r['success']:
                    results[r['id']] = r
        return results

# ================= 4. å­¦ç”Ÿä»£ç† (Qwen-Math) =================
class QwenStudent:
    def __init__(self):
        # è‡ªåŠ¨è·å–å½“å‰æœºå™¨çš„ GPU æ•°é‡
        gpu_count = torch.cuda.device_count()
        print(f"ğŸ§‘â€ğŸ“ Qwen-Math å­¦ç”Ÿåˆå§‹åŒ– (GPUs={gpu_count}, vLLM Tensor Parallel)...")
        
        self.llm = LLM(
            model=STUDENT_MODEL_PATH,
            trust_remote_code=True,
            tensor_parallel_size=gpu_count, # è‡ªåŠ¨åˆ©ç”¨å¤šå¡
            gpu_memory_utilization=0.92, 
            max_model_len=8192, 
            enforce_eager=False
        )
        self.params = SamplingParams(temperature=0.0, max_tokens=2048)

    def construct_abstraction_prompt(self, q):
        return f"""<|im_start|>user
You are a Mathematics Librarian. Your task is to classify a math problem and abstract its core pattern for retrieval.

Step 1: **Classification**
Determine which ONE of the following categories best fits the problem:
{json.dumps(VALID_TYPES)}

Step 2: **Abstraction**
Identify the core mathematical structure (the "Trigger"). 
- Ignore specific numbers ($x=5$, 30 degrees).
- Use general terms (quadratic equation, inscribed circle, modular arithmetic).
- Describe *what* the problem is asking, not *how* to solve it.

[Example]
Problem: "Find the remainder when $7^{{2023}}$ is divided by 11."
Response:
Type: Number Theory
Pattern: Calculating the remainder of a large power modulo a prime number (Euler's/Fermat's Little Theorem).

[Target]
Problem: {q}
Response:<|im_end|>
<|im_start|>assistant
"""

    # [æ–°å¢] æ‰¹é‡æŠ½è±¡åŒ–å‡½æ•°
    def batch_abstract(self, questions):
        """
        è¾“å…¥: é¢˜ç›®åˆ—è¡¨
        è¾“å‡º: list of dict {'type': ..., 'pattern': ...}
        """
        prompts = [self.construct_abstraction_prompt(q) for q in questions]
        # è¿™é‡Œ max_tokens ä¸ç”¨å¤ªé•¿ï¼ŒæŠ½è±¡æè¿°é€šå¸¸å¾ˆçŸ­
        outputs = self.llm.generate(prompts, SamplingParams(temperature=0.0, max_tokens=256), use_tqdm=True)
        
        results = []
        for output in outputs:
            text = output.outputs[0].text
            # ç®€å•çš„è§£æé€»è¾‘
            p_type = "Algebra"
            p_pattern = text
            
            # è§£æ Type
            type_match = re.search(r"Type:\s*([a-zA-Z\s&]+)", text, re.IGNORECASE)
            if type_match: p_type = type_match.group(1).strip()
            
            # è§£æ Pattern
            pat_match = re.search(r"Pattern:\s*(.+)", text, re.IGNORECASE | re.DOTALL)
            if pat_match: p_pattern = pat_match.group(1).strip()
            
            results.append({"type": p_type, "pattern": p_pattern})
        return results

    def construct_prompt(self, question, hint=None):
        content = ""
        if hint:
            content += f"Hint: {hint}\n\n"
        content += f"Problem: {question}\n\nPlease reason step by step and put your final answer within \\boxed{{}}."
        return f"<|im_start|>user\n{content}<|im_end|>\n<|im_start|>assistant\n"

    def batch_solve(self, input_data):
        """
        åˆ©ç”¨ vLLM çš„ Continuous Batching è¿›è¡Œæé€Ÿæ¨ç†ã€‚
        input_data: list of dict {'question': ..., 'hint': ...}
        """
        prompts = [self.construct_prompt(item['question'], item.get('hint')) for item in input_data]
        outputs = self.llm.generate(prompts, self.params, use_tqdm=True)
        return [out.outputs[0].text.strip() for out in outputs]

# ================= 5. ä¸»æµç¨‹æ§åˆ¶å™¨ =================
class DistillationPipeline:
    def __init__(self):
        self.db = MathNotebookDB(reset=False)
        self.evaluator = MathEvaluator() # åŒ…å«å¹¶è¡Œè¯„æµ‹åŠŸèƒ½
        self.teacher = DeepSeekTeacher()
        self.student = QwenStudent()
        
        print("ğŸ“š Loading MATH Dataset (jeggers/competition_math)...")
        self.dataset = load_dataset("jeggers/competition_math", "original", split='train')

    def run(self):
        # å®šä¹‰ç¼“å­˜æ–‡ä»¶å
        FAILED_CACHE_FILE = "failed_cases_checkpoint.json"
        
        active_failed_cases = []
        loaded_from_cache = False

        # ================= 1. å°è¯•è¯»å–æœ¬åœ°ç¼“å­˜ (æ–­ç‚¹ç»­ä¼ ) =================
        if os.path.exists(FAILED_CACHE_FILE):
            print(f"\nğŸ“‚ æ£€æµ‹åˆ°æœ¬åœ°é”™é¢˜ç¼“å­˜: {FAILED_CACHE_FILE}")
            print("â© æ­£åœ¨åŠ è½½ç¼“å­˜ï¼Œè·³è¿‡ [Phase 1] å­¦ç”Ÿè£¸è€ƒé˜¶æ®µ...")
            try:
                with open(FAILED_CACHE_FILE, "r", encoding="utf-8") as f:
                    active_failed_cases = json.load(f)
                print(f"âœ… æˆåŠŸåŠ è½½ {len(active_failed_cases)} é“é”™é¢˜ã€‚")
                loaded_from_cache = True
            except Exception as e:
                print(f"âŒ ç¼“å­˜åŠ è½½å¤±è´¥ ({e})ï¼Œå°†é‡æ–°è¿è¡Œ Phase 1ã€‚")

        # ================= 2. å¦‚æœæ²¡ç¼“å­˜ï¼Œæ­£å¸¸è¿è¡Œ Phase 1 (æŒ–æ˜é”™é¢˜) =================
        if not loaded_from_cache:
            total_len = len(self.dataset)
            indices = list(range(total_len))
            random.shuffle(indices) 
            
            # å¤„ç† SAMPLE_SIZE
            if SAMPLE_SIZE:
                indices = indices[:SAMPLE_SIZE]
                print(f"âš ï¸ Debug Mode: ä»…é‡‡æ · {SAMPLE_SIZE} æ¡æ•°æ®")
        
            batch_data = []
            print(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ•°æ®...")
            
            for i in indices:
                row = self.dataset[i]
                batch_data.append({
                    "id": f"math_{i}",
                    "question": row['problem'],
                    "ground_truth": row['solution'],
                    "original_type": row.get('type', 'Unknown'), 
                    "level": row.get('level', 'Unknown'),
                    "status": "pending", 
                    "hint": None,
                    "feedback": None
                })
            
            print(f"ğŸš€ é«˜éš¾åº¦æ•°å­¦è’¸é¦å¼€å§‹ (Full Mode, N={len(batch_data)})...")

            # --- Phase 1: æ‰¹é‡è£¸è€ƒ ---
            print("\n[Phase 1] æ‰¹é‡è£¸è€ƒ (Base Run)...")
            # GPU å¹¶è¡Œ
            base_answers = self.student.batch_solve(batch_data)
            
            # CPU å¹¶è¡Œè¯„æµ‹
            verify_pairs = [(ans, item['ground_truth']) for ans, item in zip(base_answers, batch_data)]
            verify_results = self.evaluator.batch_verify(verify_pairs)
            
            for i, is_correct in enumerate(verify_results):
                item = batch_data[i]
                if not is_correct:
                    item['wrong_ans'] = base_answers[i]
                    active_failed_cases.append(item)
            
            print(f"   -> åˆå§‹å‡†ç¡®ç‡: {1 - (len(active_failed_cases) / len(batch_data)):.2%} (é”™é¢˜æ•°: {len(active_failed_cases)})")

            # åˆæ¬¡ä¿å­˜ç¼“å­˜ (é˜²æ­¢åç»­æ­¥éª¤å´©æºƒ)
            try:
                with open(FAILED_CACHE_FILE, "w", encoding="utf-8") as f:
                    json.dump(active_failed_cases, f, ensure_ascii=False, indent=2)
            except: pass

        # ================= [æ–°å¢] 3. å­¦ç”Ÿè‡ªæˆ‘æŠ½è±¡ (Self-Abstraction) =================
        # åœ¨å»ºç«‹ç´¢å¼•å‰ï¼Œæ£€æŸ¥é”™é¢˜æ˜¯å¦å·²ç»åŒ…å«äº†æŠ½è±¡Patternã€‚å¦‚æœæ²¡æœ‰ï¼Œè®©å­¦ç”Ÿç”Ÿæˆã€‚
        # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†è®©æ£€ç´¢åº“é‡Œçš„ key å˜æˆæŠ½è±¡çš„æ•°å­¦ Patternï¼Œè€Œä¸æ˜¯å…·ä½“çš„æ•°å­—é¢˜ç›®ã€‚
        
        cases_to_abstract = [c for c in active_failed_cases if 'abstraction_pattern' not in c]
        
        if cases_to_abstract:
            print(f"\nğŸŒ€ æ­£åœ¨å¯¹ {len(cases_to_abstract)} é“é”™é¢˜è¿›è¡ŒæŠ½è±¡åŒ–é¢„å¤„ç†...")
            # æå–é¢˜ç›®æ–‡æœ¬
            raw_questions = [c['question'] for c in cases_to_abstract]
            
            # è°ƒç”¨ Student çš„æŠ½è±¡èƒ½åŠ› (éœ€ç¡®ä¿ QwenStudent ç±»ä¸­æœ‰ batch_abstract æ–¹æ³•)
            abs_results = self.student.batch_abstract(raw_questions)
            
            # å›å¡«ç»“æœ
            for c, res in zip(cases_to_abstract, abs_results):
                c['abstraction_type'] = res['type']     # å­¦ç”Ÿè®¤ä¸ºçš„ç±»å‹
                c['abstraction_pattern'] = res['pattern'] # å­¦ç”Ÿæå–çš„Pattern
            
            # æ›´æ–°ç¼“å­˜æ–‡ä»¶ (ä¿å­˜å®è´µçš„æŠ½è±¡ç»“æœ)
            print(f"ğŸ’¾ æ›´æ–°é”™é¢˜ç¼“å­˜ (å«æŠ½è±¡ä¿¡æ¯)...")
            with open(FAILED_CACHE_FILE, "w", encoding="utf-8") as f:
                json.dump(active_failed_cases, f, ensure_ascii=False, indent=2)
        else:
            print("âœ… æ‰€æœ‰é”™é¢˜å·²åŒ…å«æŠ½è±¡ä¿¡æ¯ï¼Œè·³è¿‡æŠ½è±¡åŒ–æ­¥éª¤ã€‚")

        # ================= 4. å»ºç«‹é”™é¢˜ç´¢å¼• (åŸºäºæŠ½è±¡ Pattern) =================
        # è¿™é‡Œä¼šè°ƒç”¨ä¿®æ”¹åçš„ index_failed_casesï¼Œç´¢å¼• abstraction_pattern
        self.db.index_failed_cases(active_failed_cases)

        # ================= Phase 2: å¾ªç¯è’¸é¦ (ä¿æŒä¸å˜) =================
        for round_idx in range(1, MAX_RETRY_ROUNDS + 1):
            if not active_failed_cases: break
                
            print(f"\n[Round {round_idx}] æ­£åœ¨æ”»å…‹ {len(active_failed_cases)} é“éš¾é¢˜...")

            # A. Teacher ä»‹å…¥ (ç”Ÿæˆé«˜è´¨é‡ Trigger å’Œ Strategy)
            teacher_results = self.teacher.batch_teach(active_failed_cases)
            
            ready_to_solve_cases = []
            for case in active_failed_cases:
                if case['id'] in teacher_results:
                    res = teacher_results[case['id']]
                    # è¿™é‡Œä¿å­˜äº† Teacher ç”Ÿæˆçš„ type, trigger, strategy
                    case['hint'] = res['strategy']
                    case['trigger'] = res['trigger'] 
                    case['type'] = res['type'] 
                    ready_to_solve_cases.append(case)
            
            if not ready_to_solve_cases: break

            # B. Student é‡åšåŸé¢˜ (Verification A)
            print(f"   âœï¸ Student å°è¯•åº”ç”¨æ–°ç­–ç•¥è§£åŸé¢˜...")
            new_answers = self.student.batch_solve(ready_to_solve_cases)
            
            # æ‰¹é‡éªŒè¯é‡åšç»“æœ
            verify_pairs = [(ans, c['ground_truth']) for ans, c in zip(new_answers, ready_to_solve_cases)]
            verify_results = self.evaluator.batch_verify(verify_pairs)

            candidates_for_generalization = [] 
            still_failed_cases = []
            
            for i, is_correct in enumerate(verify_results):
                case = ready_to_solve_cases[i]
                ans = new_answers[i]
                
                if is_correct:
                    candidates_for_generalization.append(case)
                else:
                    case['feedback'] = f"Strategy failed. Student output: {ans[-200:]}..." 
                    case['wrong_ans'] = ans
                    still_failed_cases.append(case)
            
            print(f"   -> åŸé¢˜ä¿®å¤ç‡: {len(candidates_for_generalization)}/{len(ready_to_solve_cases)}")

            # C. æ³›åŒ–éªŒè¯ (Verification B)
            final_success_buffer = []
            
            if candidates_for_generalization:
                print(f"   âš”ï¸ è¿›å…¥æ³›åŒ–éªŒè¯é—¨æ§ (Based on Abstract Pattern)...")
                
                verify_tasks = []
                for case in candidates_for_generalization:
                    # [ä¿®æ”¹] ä½¿ç”¨ filter_type è¿›è¡Œæ›´ç²¾å‡†çš„æ£€ç´¢
                    # é€»è¾‘ï¼šç”¨ Teacher ç”Ÿæˆçš„ Trigger å»æœ Student æŠ½è±¡å‡ºçš„ Patternåº“
                    # å¹¶ä¸”å¼ºåˆ¶è¦æ±‚é¢˜ç›®ç±»å‹ä¸€è‡´ (case['type'] æ¥è‡ª Teacher)
                    neighbor = self.db.search_similar_failed_case(
                        trigger_text=case['trigger'], 
                        exclude_id=case['id'],
                        filter_type=case.get('type') 
                    )
                    
                    # [å›é€€æœºåˆ¶] å¦‚æœåŒç±»å‹æ²¡æœåˆ°ï¼Œå°è¯•ä¸é™åˆ¶ç±»å‹æœä¸€æ¬¡
                    if not neighbor:
                        neighbor = self.db.search_similar_failed_case(
                            trigger_text=case['trigger'], 
                            exclude_id=case['id'],
                            filter_type=None
                        )

                    if neighbor:
                        verify_tasks.append({
                            "question": neighbor['question'], # è¿™é‡Œå–å‡ºæ¥çš„æ˜¯åŸé¢˜æ–‡æœ¬
                            "hint": case['hint'],             # ä½¿ç”¨åŸé¢˜çš„ Strategy
                            "ground_truth": neighbor['ground_truth'],
                            "source_case": case 
                        })

                if verify_tasks:
                    # GPU å¹¶è¡Œè§£æ³›åŒ–é¢˜
                    verify_answers = self.student.batch_solve(verify_tasks)
                    
                    # CPU å¹¶è¡ŒéªŒè¯æ³›åŒ–ç»“æœ
                    v_pairs = [(ans, t['ground_truth']) for ans, t in zip(verify_answers, verify_tasks)]
                    v_results = self.evaluator.batch_verify(v_pairs)
                    
                    for i, is_correct in enumerate(v_results):
                        task = verify_tasks[i]
                        if is_correct:
                            final_success_buffer.append({
                                "original_q": task['source_case']['question'],
                                "rule_text": task['source_case']['hint'],
                                "trigger": task['source_case']['trigger'],
                                "type": task['source_case']['type'] # å­˜å…¥ Teacher ç¡®å®šçš„ç±»å‹
                            })
            
            # D. å…¥åº“
            if final_success_buffer:
                self.db.save_experience_batch(final_success_buffer)
            
            active_failed_cases = still_failed_cases

        print("\n" + "="*50)
        print(f"ğŸ† è®­ç»ƒç»“æŸã€‚æ•°æ®åº“ä¸­ç°æœ‰ {self.db.collection.count()} æ¡é«˜ä»·å€¼æ•°å­¦ç­–ç•¥ã€‚")

if __name__ == "__main__":
    try:
        import gc
        gc.collect()
        torch.cuda.empty_cache()
    except:
        pass

    pipeline = DistillationPipeline()
    pipeline.run()

    print("ğŸ‘‹ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ­£åœ¨å¼ºåˆ¶å…³é—­ vLLM è¿›ç¨‹...")
    sys.exit(0)
